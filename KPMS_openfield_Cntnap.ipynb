{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb68b0f-e8c0-4e30-a151-9c336fa33a8e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 1. Deeplabcut analysis (Fig. 5 E,F,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e7464-7405-46d5-81fa-0907f931b9ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gaitAnalysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36769702-cc27-434f-b735-8b0be4d8db0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_dir = r'data\\openfield_Cntnap'\n",
    "dataFolder = os.path.join(root_dir,'Data')\n",
    "\n",
    "fps = 40\n",
    "\n",
    "\"\"\"analysis\n",
    "    1. moving distance\n",
    "    2. running speed distribution/average\n",
    "    3. angular speed distribution/average\n",
    "    4. time spend in the middle (future). A gui defining boudaries of the field based on user input\n",
    "     \"\"\"\n",
    "\n",
    "savemotionpath = os.path.join(root_dir, 'Summary', 'DLC')\n",
    "groups = ['Ctrl', 'Exp']\n",
    "behavior = 'openfield'\n",
    "DLCSum = DLCSummary(root_dir, fps, groups,behavior)\n",
    "\n",
    "    # basic motor-related analysis\n",
    "    #\n",
    "DLCSum.center_analysis(savemotionpath)\n",
    "\n",
    "DLCSum.motion_analysis(savemotionpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db27696-d12c-465a-b1c1-417f65ee66ed",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Keypoint_moseq analysis (Fig, 5 G,I,O)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841003b7",
   "metadata": {},
   "source": [
    "## Project setup\n",
    "Create a new project directory with a keypoint-MoSeq `config.yml` file."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b31de4a47629c09c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keypoint_moseq as kpms\n",
    "\n",
    "project_dir = r'project/folder'\n",
    "config = lambda: kpms.load_config(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b551d",
   "metadata": {},
   "source": [
    "### Options 3: Manual setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b0b1a",
   "metadata": {
    "mystnb": {
     "code_prompt_hide": "Custom setup",
     "code_prompt_show": "Custom setup"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# open field\n",
    "bodyparts=['nose','left ear', 'right ear','head','left hand', 'right hand','spine 1', 'spine 2',\n",
    "    'spine 3','left foot','right foot',\n",
    "    'tail 1', 'tail 2', 'tail 3']\n",
    "\n",
    "\n",
    "# open field\n",
    "skeleton=[\n",
    "    ['tail 3', 'tail 2'],\n",
    "    ['tail 2', 'tail 1'],\n",
    "    ['tail 1', 'spine 3'],\n",
    "    ['spine 3', 'left foot'],\n",
    "    ['spine 3', 'right foot'],\n",
    "    ['spine 3', 'spine 2'],\n",
    "    ['spine 2', 'spine 1'],\n",
    "    ['spine 1', 'left hand'],\n",
    "    ['spine 1', 'right hand'],\n",
    "    ['spine 1', 'head'],\n",
    "    ['nose', 'head'],\n",
    "    ['left ear', 'head'],\n",
    "    ['right ear', 'head'],]\n",
    "\n",
    "\n",
    "video_dir = r'/project/folder/videos/'\n",
    "kpms.setup_project(\n",
    "    project_dir,\n",
    "    video_dir=video_dir,\n",
    "    bodyparts=bodyparts,\n",
    "    skeleton=skeleton, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9d6e0",
   "metadata": {},
   "source": [
    "## Edit the config file\n",
    "\n",
    "The config can be edited in a text editor or using the function `kpms.update_config`, as shown below. In general, the following parameters should be specified for each project:\n",
    "\n",
    "- `bodyparts` (name of each keypoint; automatically imported from SLEAP/DeepLabCut)\n",
    "- `use_bodyparts` (subset of bodyparts to use for modeling, set to all bodyparts by default; for mice we recommend excluding the tail)\n",
    "- `anterior_bodyparts` and `posterior_bodyparts` (used for rotational alignment)\n",
    "- `video_dir` (directory with videos of each experiment)\n",
    "\n",
    "Edit the config as follows for the [example DeepLabCut dataset](https://drive.google.com/drive/folders/1UNHQ_XCQEKLPPSjGspRopWBj6-YNDV6G?usp=share_link):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kpms.update_config(\n",
    "    project_dir, \n",
    "    video_dir = video_dir,\n",
    "    anterior_bodyparts=['nose'],\n",
    "    posterior_bodyparts=['tail 1'],\n",
    "    use_bodyparts=['nose','left ear', 'right ear','head','left hand', 'right hand','spine 1', 'spine 2',\n",
    "    'spine 3','left foot','right foot', 'tail 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27d86b",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Data can be loaded from DeepLabCut, SLEAP or from any another source as long as it has the following format, where K is the number of keypoints and D is 2 or 3\n",
    "- `coordinates`: dict from session names to keypoint coordinate arrays of shape (T,K,D). Each key should start with its video name (e.g. `coordinates[\"experiment1_etc\"]` would correspond to `experiment1.avi`. In general this will already be true if importing from SLEAP or DeepLabCut).\n",
    "    \n",
    "- `confidences`: dict from session names to **nonnegative** keypoint confidence arrays of shape (T,K). Confidences are optional (they are used to set the error prior for each observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea7d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_data_path= video_dir\n",
    "\n",
    "# load data (e.g. from DeepLabCut)\n",
    "\n",
    "coordinates, confidences, bodyparts = kpms.load_keypoints(keypoint_data_path, 'deeplabcut')\n",
    "\n",
    "# format data for modeling\n",
    "data, metadata = kpms.format_data(coordinates, confidences, **config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinates.keys()\n",
    "#confidences\n",
    "#bodyparts\n",
    "#data.keys()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f33ff",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "The purpose of calibration is to learn the relationship between error and keypoint confidence scores. The resulting regression coefficients (`slope` and `intercept`) are used during modeling to set the noise prior on a per-frame, per-keypoint basis. One can also adjust the `confidence_threshold` parameter at this step, which is used to define outlier keypoints for PCA and model initialization. **This step can be skipped for the demo data** since the config already includes suitable regression coefficients.\n",
    "\n",
    "- Run the cell below. A widget should appear with a video frame on the left.\n",
    "    - *If the widget doesn't render, try using jupyter lab instead of jupyter notebook*\n",
    "    \n",
    "- Annotate each frame with the correct location of the labeled bodypart\n",
    "    - Left click to specify the correct location - an \"X\" should appear.\n",
    "    - Use the arrow buttons to annotate additional frames.\n",
    "    - Each annotation adds a point to the right-hand scatter plot. \n",
    "    - Continue until the regression line stabilizes.\n",
    "   \n",
    "- At any point, adjust the confidence threshold by clicking on the scatter plot.\n",
    "\n",
    "- Use the \"save\" button to update the config and store your annotations to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a177798",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.noise_calibration(project_dir, coordinates, confidences, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711edaa",
   "metadata": {},
   "source": [
    "## Fit PCA\n",
    "\n",
    "Run the cell below to fit a PCA model to aligned and centered keypoint coordinates. The model is saved to ``{project_dir}/pca.p`` and can be reloaded using ``kpms.load_pca``. Two plots are generated: a cumulative [scree plot](https://en.wikipedia.org/wiki/Scree_plot) and a depiction of each PC, where translucent nodes/edges represent the mean pose and opaque nodes/edges represent a perturbation in the direction of the PC. \n",
    "\n",
    "- After fitting, edit `latent_dimension` in the config. \n",
    "- A good heuristic is the number of dimensions needed to explain 90% of variance, or 10 dimensions - whichever is lower.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddae668",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = kpms.fit_pca(**data, **config(),parallel_message_passing=False)\n",
    "kpms.save_pca(pca, project_dir)\n",
    "\n",
    "kpms.print_dims_to_explain_variance(pca, 0.9)\n",
    "kpms.plot_scree(pca, project_dir=project_dir)\n",
    "kpms.plot_pcs(pca, project_dir=project_dir, **config())\n",
    "\n",
    "# use the following to load an already \n",
    "# pca = kpms.load_pca(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f36536",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.update_config(project_dir, latent_dim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81278a47",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "Fitting a keypoint-MoSeq model involves:\n",
    "1. **Initialization:** Auto-regressive (AR) parameters and syllable sequences are randomly initialized using pose trajectories from PCA.\n",
    "2. **Fitting an AR-HMM:** The AR parameters, transition probabilities and syllable sequences are iteratively updated through Gibbs sampling. \n",
    "3. **Fitting the full model:** All parameters, including both the AR-HMM as well as centroid, heading, noise-estimates and continuous latent states (i.e. PCA trajectories) are iteratively updated through Gibbs sampling. This step is especially useful for noisy data.\n",
    "4. **Apply the trained model:** The learned model parameters are used to infer a syllable sequence for each experiment. This step should always be applied at the end of model fitting, and it can also be used later on to infer syllable sequences for newly added data.\n",
    "\n",
    "## Setting hyperparameters\n",
    "\n",
    "There are two ways to change hyperparameters:\n",
    "1. Update the config using `kpms.update_config` and then re-initialize the model\n",
    "2. Change the model directly via `kpms.update_hypparams`\n",
    "\n",
    "In general, the main hyperparam that needs to be adjusted is **kappa**, which sets the time-scale of syllables. Higher kappa leads to longer syllables. For this tutorial we chose kappa values that yielded a median syllable duration of 400ms (12 frames). In general, you will need to tune kappa for each new dataset based on the intended syllable time-scale. **You will need to pick two kappas: one for AR-HMM fitting and one for the full model.**\n",
    "- We recommend iteratively updating kappa and refitting the model until the target syllable time-scale is attained.  \n",
    "- Model fitting can be stopped at any time by interrupting the kernel, and kappa can be adjusted as described above.\n",
    "- The full model will generally require a lower value of kappa to yield the same target syllable durations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a93ca",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098ad94-32e1-4c80-8ffe-46572d5d110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally update kappa in the config before initializing \n",
    "# kpms.update_config(project_dir=project_dir, kappa=NUMBER)\n",
    "\n",
    "# initialize the model\n",
    "from jax_moseq.utils import set_mixed_map_iters\n",
    "set_mixed_map_iters(6)\n",
    "\n",
    "kpms.update_config(project_dir,kappa = 1e14)\n",
    "model = kpms.init_model(data, pca=pca, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15304268",
   "metadata": {},
   "source": [
    "## Fitting an AR-HMM\n",
    "\n",
    "In addition to fitting an AR-HMM, the function below:\n",
    "- generates a name for the model and a new directory in `project_dir`\n",
    "- saves a checkpoint every 10 iterations from which fitting can be restarted\n",
    "    - a single checkpoint file contains the full history of fitting, and can be used to restart fitting from any iteration\n",
    "- plots the progress of fitting every 10 iterations, including\n",
    "    - the distributions of syllable frequencies and durations for the most recent iteration\n",
    "    - the change in median syllable duration across fitting iterations\n",
    "    - the syllable sequence across iterations in a random window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f0250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_ar_iters = 50\n",
    "\n",
    "model, model_name = kpms.fit_model(\n",
    "    model, data, metadata, project_dir,\n",
    "    ar_only=True, num_iters=num_ar_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab39112",
   "metadata": {},
   "source": [
    "## Fitting the full model\n",
    "\n",
    "The following code fits a full keypoint-MoSeq model, using the results of AR-HMM fitting for initialization\n",
    "- If using your own data, you may need to try a few values of kappa at this step. \n",
    "- Use `kpms.revert` to resume from the same starting point each time you restart fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model checkpoint\n",
    "num_ar_iters = 50\n",
    "from jax_moseq.utils import set_mixed_map_iters\n",
    "set_mixed_map_iters(6)\n",
    "#model_name = '2024_05_12-07_36_17'\n",
    "model, data, metadata, current_iter = kpms.load_checkpoint(\n",
    "    project_dir, model_name, iteration=num_ar_iters)\n",
    "\n",
    "# modify kappa to maintain the desired syllable time-scale\n",
    "model = kpms.update_hypparams(model, kappa=1e9)\n",
    "\n",
    "# run fitting for an additional 200 iters\n",
    "model = kpms.fit_model(\n",
    "    model, data, metadata, project_dir, model_name, ar_only=False, \n",
    "    start_iter=current_iter, num_iters=current_iter+300,parallel_message_passing=False)[0]\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f37d1",
   "metadata": {},
   "source": [
    "## Apply the trained model\n",
    "\n",
    "The code below infers a syllable sequence for each experiment. The results are saved in `{project_dir}/{name}/results.h5`. \n",
    "- The default assumption is that `coordinates` and `confidences` are the same data that were used for model fitting.\n",
    "\n",
    "To infer syllable sequences for new data:\n",
    "- Run ``kpms.apply_model`` with `use_saved_states=False` and pass in a pca model\n",
    "- Results for the new experiments will be added to the existing `results.h5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8cf24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the most recent model checkpoint and pca object\n",
    "\n",
    "model_name = '2024_05_12-07_36_17'\n",
    "project_dir = r'project/folder'\n",
    "#config = lambda: kpms.load_config(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.read('jax_enable_x64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7442436",
   "metadata": {},
   "source": [
    "## Visualize syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04baed",
   "metadata": {},
   "source": [
    "## Trajectory plots\n",
    "Generate plots showing the average trajectory of poses associated with each given syllable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.reindex_syllables_in_checkpoint(project_dir, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac97b4-eb71-4e70-83f4-9a655ccc7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '2024_05_12-07_36_17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800457a-fec0-4803-bfdd-48e49aa0262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the most recent model checkpoint\n",
    "model, data, metadata, current_iter = kpms.load_checkpoint(project_dir, model_name)\n",
    "\n",
    "# extract results\n",
    "results = kpms.extract_results(model, metadata, project_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f78ef9-b5f8-4b4f-a1c7-122dfaa92561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpms.save_results_as_csv(results, project_dir, model_name)\n",
    "#keypoint_moseq.viz.plot_duration_distribution\n",
    "#kpms.plot_syllable_frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0abec9a-6e31-4fce-a360-e37d22c424b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10eecb4-9c84-4940-bbea-6fda092cc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "temp_syll_include = np.array([x for x in range(24)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc6bf6",
   "metadata": {},
   "source": [
    "## Crowd & grid movies\n",
    "Generate video clips showing examples of each syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42549fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpms.generate_trajectory_plots?\n",
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a025cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.generate_trajectory_plots(coordinates, results, project_dir, model_name,fps=40,**config())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05c901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kpms.generate_grid_movies(results, project_dir, model_name, pre=30, post=30,coordinates=coordinates,fps=40,overlay_keypoints=True,**config())\n",
    "# rows=3, cols=5, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6cece-2e30-46f5-b28b-892dfd79d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized plot_similarity_dendrogram to save svg files\n",
    "from keypoint_moseq.io import load_results, _get_path\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "def plot_similarity_dendrogram_customize(\n",
    "    coordinates,\n",
    "    results,\n",
    "    project_dir=None,\n",
    "    model_name=None,\n",
    "    save_path=None,\n",
    "    metric=\"cosine\",\n",
    "    pre=5,\n",
    "    post=15,\n",
    "    min_frequency=0.005,\n",
    "    min_duration=3,\n",
    "    bodyparts=None,\n",
    "    use_bodyparts=None,\n",
    "    density_sample=False,\n",
    "    sampling_options={\"n_neighbors\": 50},\n",
    "    figsize=(6, 3),\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Plot a dendrogram showing the similarity between syllable trajectories.\n",
    "\n",
    "    The dendrogram is saved to `{save_path}` if it is provided, or\n",
    "    else to `{project_dir}/{model_name}/similarity_dendrogram.pdf`. Plot-\n",
    "    related parameters are described below. For the remaining parameters\n",
    "    see (:py:func:`keypoint_moseq.util.get_typical_trajectories`)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinates: dict\n",
    "        Dictionary mapping recording names to keypoint coordinates as\n",
    "        ndarrays of shape (n_frames, n_bodyparts, [2 or 3]).\n",
    "\n",
    "    results: dict\n",
    "        Dictionary containing modeling results for a dataset (see\n",
    "        :py:func:`keypoint_moseq.fitting.extract_results`).\n",
    "\n",
    "    project_dir: str, default=None\n",
    "        Project directory. Required to save figure if `save_path` is None.\n",
    "\n",
    "    model_name: str, default=None\n",
    "        Model name. Required to save figure if `save_path` is None.\n",
    "\n",
    "    save_path: str, default=None\n",
    "        Path to save the dendrogram plot (do not include an extension).\n",
    "        If None, the plot will be saved  to\n",
    "        `{project_dir}/{name}/similarity_dendrogram.[pdf/png]`.\n",
    "\n",
    "    metric: str, default='cosine'\n",
    "        Distance metric to use. See :py:func:`scipy.spatial.pdist` for options.\n",
    "\n",
    "    figsize: tuple of float, default=(10,5)\n",
    "        Size of the dendrogram plot.\n",
    "    \"\"\"\n",
    "    save_path = _get_path(project_dir, model_name, save_path, \"similarity_dendrogram\")\n",
    "\n",
    "    distances, syllable_ixs = kpms.util.syllable_similarity(\n",
    "        coordinates,\n",
    "        results,\n",
    "        metric,\n",
    "        pre,\n",
    "        post,\n",
    "        min_frequency,\n",
    "        min_duration,\n",
    "        bodyparts,\n",
    "        use_bodyparts,\n",
    "        density_sample,\n",
    "        sampling_options,\n",
    "    )\n",
    "\n",
    "    Z = linkage(squareform(distances), \"complete\")\n",
    "\n",
    "    file_path = save_path + \".csv\"\n",
    "    with open(file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(Z)\n",
    "\n",
    "    print(\"Matrix saved to\", file_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    labels = [f\"Syllable {s}\" for s in syllable_ixs]\n",
    "    dendrogram(Z, labels=labels, leaf_font_size=10, ax=ax, leaf_rotation=90)\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color(\"lightgray\")\n",
    "    ax.set_title(\"Syllable similarity\")\n",
    "    fig.set_size_inches(figsize)\n",
    "    plt.tight_layout()\n",
    "    print(f\"Saving dendrogram plot to {save_path}\")\n",
    "    for ext in [\"pdf\", \"png\", \"svg\"]:\n",
    "        plt.savefig(save_path + \".\" + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af619a81-47af-408b-9ffa-cf3067f1e62b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_similarity_dendrogram_customize(coordinates, results, project_dir, model_name, figsize=(6, 4),**config())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syllables reordered in similarity\n",
    "\n",
    "# edit the syllable sequence according to the similarity\n",
    "syll_sim = [21, 20, 10,23,2,24,6, 19, 3, 15, 8, 27, 5, 13, 7, 17, 26, 4, 11, 25, 18, 22, 16, 12,0,1,9,14] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050df601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign groups\n",
    "index_file=kpms.interactive_group_setting(project_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.label_syllables(project_dir, model_name, moseq_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495dede-e7e6-4bfa-80fc-3eda1620038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5275141",
   "metadata": {},
   "outputs": [],
   "source": [
    "moseq_df = kpms.compute_moseq_df(project_dir, model_name, smooth_heading=True) \n",
    "moseq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d883ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = os.path.join(project_dir, model_name) # directory to save the moseq_df dataframe\n",
    "moseq_df.to_csv(os.path.join(save_dir, 'moseq_df.csv'), index=False)\n",
    "print('Saved `moseq_df` dataframe to', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efea650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_df = kpms.compute_stats_df(\n",
    "    project_dir,\n",
    "    model_name,\n",
    "    moseq_df, \n",
    "    min_frequency=0.005,       # threshold frequency for including a syllable in the dataframe\n",
    "    groupby=['group', 'name'], # column(s) to group the dataframe by\n",
    "    fps=40)                    # frame rate of the video from which keypoints were inferred\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382cebde-5e56-45ce-a632-c4abc1ca4754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = os.path.join(project_dir, model_name)\n",
    "stats_df.to_csv(os.path.join(save_dir, 'stats_df.csv'), index=False)\n",
    "print('Saved `stats_df` dataframe to', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eafbc-cf44-4f65-a15f-bf73c4660efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_syll_stats_with_sem(\n",
    "    stats_df,\n",
    "    project_dir,\n",
    "    model_name,\n",
    "    save_dir=None,\n",
    "    plot_sig=True,\n",
    "    thresh=0.05,\n",
    "    stat=\"frequency\",\n",
    "    order=\"stat\",\n",
    "    groups=None,\n",
    "    ctrl_group=None,\n",
    "    exp_group=None,\n",
    "    colors=None,\n",
    "    join=False,\n",
    "    figsize=(8, 4),\n",
    "):\n",
    "    \"\"\"Plot syllable statistics with standard error of the mean.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stats_df : pandas.DataFrame\n",
    "        the dataframe that contains kinematic data and the syllable label\n",
    "    project_dir : str\n",
    "        the project directory\n",
    "    model_name : str\n",
    "        the model directory name\n",
    "    save_dir : str\n",
    "        the path to save the analysis plots\n",
    "    plot_sig : bool, optional\n",
    "        whether to plot the significant syllables, by default True\n",
    "    thresh : float, optional\n",
    "        the threshold for significance, by default 0.05\n",
    "    stat : str, optional\n",
    "        the statistic to plot, by default 'frequency'\n",
    "    ordering : str, optional\n",
    "        the ordering of the syllables, by default 'stat'\n",
    "    groups : list, optional\n",
    "        the list of groups to plot, by default None\n",
    "    ctrl_group : str, optional\n",
    "        the control group, by default None\n",
    "    exp_group : str, optional\n",
    "        the experimental group, by default None\n",
    "    colors : list, optional\n",
    "        the list of colors to use for each group, by default None\n",
    "    join : bool, optional\n",
    "        whether to join the points with a line, by default False\n",
    "    figsize : tuple, optional\n",
    "        the figure size, by default (8, 4)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        the figure object\n",
    "    legend : matplotlib.legend.Legend\n",
    "        the legend object\n",
    "    \"\"\"\n",
    "\n",
    "    # get significant syllables\n",
    "    sig_sylls = None\n",
    "\n",
    "    if plot_sig and len(stats_df[\"group\"].unique()) > 1:\n",
    "        # run kruskal wallis and dunn's test\n",
    "        df_k_real, dunn_results_df, sig_pairs = kpms.run_kruskal(stats_df, statistic=stat, thresh=thresh)\n",
    "        # plot significant syllables for control and experimental group\n",
    "        if ctrl_group is not None and exp_group is not None:\n",
    "            # check if the group pair is in the sig pairs dict\n",
    "            if (ctrl_group, exp_group) in sig_pairs.keys():\n",
    "                sig_sylls = sig_pairs.get((ctrl_group, exp_group))\n",
    "            # flip the order of the groups\n",
    "            else:\n",
    "                sig_sylls = sig_pairs.get((exp_group, ctrl_group))\n",
    "        else:\n",
    "            print(\n",
    "                \"No control or experimental group specified. Not plotting significant syllables.\"\n",
    "            )\n",
    "    #print(df_k_real.keys())\n",
    "    #print(df_k_real[\"p_adj\"])\n",
    "    \n",
    "    xlabel = f\"Syllables sorted by {stat}\"\n",
    "    if order == \"diff\":\n",
    "        xlabel += \" difference\"\n",
    "    ordering, groups, colors, figsize = _validate_and_order_syll_stats_params(\n",
    "        stats_df,\n",
    "        stat=stat,\n",
    "        order=order,\n",
    "        groups=groups,\n",
    "        ctrl_group=ctrl_group,\n",
    "        exp_group=exp_group,\n",
    "        colors=colors,\n",
    "        figsize=figsize,\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "    print(stat)\n",
    "    # plot each group's stat data separately, computes groupwise SEM, and orders data based on the stat/ordering parameters\n",
    "    hue = \"group\" if groups is not None else None\n",
    "    ax = sns.pointplot(\n",
    "        data=stats_df,\n",
    "        x=\"syllable\",\n",
    "        y=stat,\n",
    "        hue=hue,\n",
    "        order=ordering,\n",
    "        errorbar=(\"se\"),\n",
    "        ax=ax,\n",
    "        hue_order=groups,\n",
    "        palette=colors,\n",
    "    )\n",
    "\n",
    "    # extract data from plot\n",
    "    lines = ax.get_lines()\n",
    "\n",
    "    syllables = lines[0].get_xdata()\n",
    "    KO_freq = lines[0].get_ydata()\n",
    "    KO_high = []\n",
    "    KO_low = []\n",
    "    for k in range(len(syllables)):\n",
    "        err=lines[k+1].get_ydata()\n",
    "        KO_low.append(err[0])\n",
    "        KO_high.append(err[1])\n",
    "\n",
    "    WT_freq = lines[len(syllables)+1].get_ydata()\n",
    "    \n",
    "    WT_high = []\n",
    "    WT_low = []\n",
    "    for k in range(len(syllables)):\n",
    "        err=lines[len(syllables)+k+2].get_ydata()\n",
    "        WT_low.append(err[0])\n",
    "        WT_high.append(err[1])\n",
    "    if_sig = []\n",
    "    for k in range(len(syllables)):\n",
    "        if k in sig_sylls:\n",
    "            if_sig.append(True)\n",
    "        else:\n",
    "            if_sig.append(False)\n",
    "    #save to data frame\n",
    "    \n",
    "    df = {\n",
    "        'WT_frequency':WT_freq,\n",
    "        'WT_error_high':WT_high,\n",
    "        'WT_error_low':WT_low,\n",
    "        'KO_frequency':KO_freq,\n",
    "        'KO_error_high':KO_high,\n",
    "        'KO_error_low':KO_low,\n",
    "        'significancy':if_sig,\n",
    "        'p_value':df_k_real[\"p_adj\"]\n",
    "    }\n",
    "    df=pd.DataFrame(df)\n",
    "    save_name = f\"{stat}_{order}_stats.csv\"\n",
    "    save_path = os.path.join(project_dir, model_name,save_name)\n",
    "    df.to_csv(save_path)\n",
    "    # where some data has already been plotted to ax\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    # add syllable labels if they exist\n",
    "    syll_names = kpms.get_syllable_names(project_dir, model_name, ordering)\n",
    "    plt.xticks(range(len(syll_names)), syll_names, rotation=90)\n",
    "\n",
    "    # if a list of significant syllables is given, mark the syllables above the x-axis\n",
    "    if sig_sylls is not None:\n",
    "        markings = []\n",
    "        for s in sig_sylls:\n",
    "            markings.append(ordering.index(s))\n",
    "        plt.scatter(markings, [-0.005] * len(markings), color=\"r\", marker=\"*\")\n",
    "\n",
    "        # manually define a new patch\n",
    "        patch = Line2D(\n",
    "            [],\n",
    "            [],\n",
    "            color=\"red\",\n",
    "            marker=\"*\",\n",
    "            markersize=9,\n",
    "            label=\"Significant Syllable\",\n",
    "        )\n",
    "        handles.append(patch)\n",
    "\n",
    "    # add legend and axis labels\n",
    "    legend = ax.legend(handles=handles, frameon=False, bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    sns.despine()\n",
    "\n",
    "    # save the figure\n",
    "    plot_name = f\"{stat}_{order}_stats\"\n",
    "    kpms.save_analysis_figure(fig, plot_name, project_dir, model_name, save_dir)\n",
    "    return fig, legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607b3ce-85f9-4958-a594-8a2e7284ed8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def _validate_and_order_syll_stats_params(\n",
    "    complete_df,\n",
    "    stat=\"frequency\",\n",
    "    order=\"stat\",\n",
    "    groups=None,\n",
    "    ctrl_group=None,\n",
    "    exp_group=None,\n",
    "    colors=None,\n",
    "    figsize=(10, 5),\n",
    "):\n",
    "    if not isinstance(figsize, (tuple, list)):\n",
    "        print(\n",
    "            \"Invalid figsize. Input a integer-tuple or list of len(figsize) = 2. Setting figsize to (10, 5)\"\n",
    "        )\n",
    "        figsize = (10, 5)\n",
    "\n",
    "    unique_groups = complete_df[\"group\"].unique()\n",
    "\n",
    "    if groups is None or len(groups) == 0:\n",
    "        groups = unique_groups\n",
    "    elif isinstance(groups, str):\n",
    "        groups = [groups]\n",
    "\n",
    "    if isinstance(groups, (list, tuple, np.ndarray)):\n",
    "        diff = set(groups) - set(unique_groups)\n",
    "        if len(diff) > 0:\n",
    "            groups = unique_groups\n",
    "\n",
    "    if stat.lower() not in complete_df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Invalid stat entered: {stat}. Must be a column in the supplied dataframe.\"\n",
    "        )\n",
    "\n",
    "    if order == \"stat\":\n",
    "        ordering, _ = kpms.sort_syllables_by_stat(complete_df, stat=stat)\n",
    "    elif order == \"diff\":\n",
    "        if (\n",
    "            ctrl_group is None\n",
    "            or exp_group is None\n",
    "            or not np.all(np.isin([ctrl_group, exp_group], groups))\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                f\"Attempting to sort by {stat} differences, but {ctrl_group} or {exp_group} not in {groups}.\"\n",
    "            )\n",
    "        ordering = kpms.sort_syllables_by_stat_difference(\n",
    "            complete_df, ctrl_group, exp_group, stat=stat\n",
    "        )\n",
    "    if colors is None:\n",
    "        colors = []\n",
    "    if len(colors) == 0 or len(colors) != len(groups):\n",
    "        colors = sns.color_palette(n_colors=len(groups))\n",
    "\n",
    "    return ordering, groups, colors, figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da03705-6972-40d2-a41c-a090e285d6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "fig,legend=plot_syll_stats_with_sem(\n",
    "    stats_df, project_dir, model_name,\n",
    "    plot_sig=True,    # whether to mark statistical significance with a star\n",
    "    thresh=0.05,      # significance threshold\n",
    "    stat='frequency', # statistic to be plotted (e.g. 'duration' or 'velocity_px_s_mean')\n",
    "    order='stat',  # order syllables by overall frequency (\"stat\") or degree of difference (\"diff\")\n",
    "    ctrl_group='Ctrl',   # name of the control group for statistical testing\n",
    "    exp_group='cKO',\n",
    "    colors = [(0,0,0), (237/255,28/255,36/255) ],# name of the experimental group for statistical testing\n",
    "    figsize=(8, 6),   # figure size    \n",
    "    groups=stats_df['group'].unique()\n",
    ");\n",
    "#ctrl_group='WT',   # name of the control group for statistical testing\n",
    "    #xp_group='cntnap',    # name of the experimental group for statistical testing\n",
    "#groups=stats_df['group'].unique(),\n",
    "savefigpath = os.path.join(project_dir, model_name, 'figures')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(savefigpath,'freq_stat_stats.svg'))\n",
    "fig.savefig(os.path.join(savefigpath,'freq_stat_stats.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e8615-040f-4cf0-9696-b5fb4a4e89a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sex difference\n",
    "kpms.plot_syll_stats_with_sem(\n",
    "    stats_df_male, project_dir, model_name,\n",
    "    plot_sig=True,    # whether to mark statistical significance with a star\n",
    "    thresh=0.05,      # significance threshold\n",
    "    stat='frequency', # statistic to be plotted (e.g. 'duration' or 'velocity_px_s_mean')\n",
    "    order='stat',     # order syllables by overall frequency (\"stat\") or degree of difference (\"diff\")\n",
    "    ctrl_group='WT_F',   # name of the control group for statistical testing\n",
    "    exp_group='Mut_F',    # name of the experimental group for statistical testing\n",
    "    figsize=(8,8),   # figure size    \n",
    "    groups=stats_df['group'].unique()\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7ea30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use a temp stats_df, replace groups with different animal ID, then plot individually\n",
    "sub_stats_df = stats_df.copy()\n",
    "sub_stats_df.drop(columns=['group'], inplace=True)\n",
    "subject = []\n",
    "for ii in range(stats_df.shape[0]):\n",
    "    subject.append(stats_df['name'][ii][27:32])\n",
    "    \n",
    "sub_stats_df['group'] = subject\n",
    "sub_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e6060-197d-45b9-819d-a3e1763d5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_transition_bigram_svg(\n",
    "    project_dir,\n",
    "    model_name,\n",
    "    group,\n",
    "    trans_mats,\n",
    "    syll_include,\n",
    "    save_dir=None,\n",
    "    normalize=\"bigram\",\n",
    "    figsize=(12, 6),\n",
    "    show_syllable_names=True,\n",
    "):\n",
    "    \"\"\"Visualize the transition matrices for each group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group : list or np.ndarray\n",
    "        the groups in the project\n",
    "    trans_mats : list\n",
    "        the list of transition matrices for each group\n",
    "    normalize : str, optional\n",
    "        the method to normalize the transition matrix, by default 'bigram'\n",
    "    figsize : tuple, optional\n",
    "        the figure size, by default (12,6)\n",
    "    show_syllable_names : bool, optional\n",
    "        whether to show just syllable indexes (False) or syllable indexes and\n",
    "        names (True)\n",
    "    \"\"\"\n",
    "    if show_syllable_names:\n",
    "        syll_names = get_syllable_names(project_dir, model_name, syll_include)\n",
    "    else:\n",
    "        syll_names = [f\"{ix}\" for ix in syll_include]\n",
    "\n",
    "    # infer max_syllables\n",
    "    max_syllables = trans_mats[0].shape[0]\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        1, len(group), figsize=figsize, sharex=False, sharey=True\n",
    "    )\n",
    "    title_map = dict(bigram=\"Bigram\", columns=\"Incoming\", rows=\"Outgoing\")\n",
    "    color_lim = max([x.max() for x in trans_mats])\n",
    "    if len(group) == 1:\n",
    "        axs = [ax]\n",
    "    else:\n",
    "        axs = ax.flat\n",
    "    for i, g in enumerate(group):\n",
    "        h = axs[i].imshow(\n",
    "            trans_mats[i][:max_syllables, :max_syllables],\n",
    "            cmap=\"cubehelix\",\n",
    "            vmax=color_lim,\n",
    "        )\n",
    "        if i == 0:\n",
    "            axs[i].set_ylabel(\"Incoming syllable\")\n",
    "            plt.yticks(np.arange(len(syll_include)), syll_names)\n",
    "        cb = fig.colorbar(h, ax=axs[i], fraction=0.046, pad=0.04)\n",
    "        cb.set_label(f\"{title_map[normalize]} transition probability\")\n",
    "        axs[i].set_xlabel(\"Outgoing syllable\")\n",
    "        axs[i].set_title(g)\n",
    "        axs[i].set_xticks(\n",
    "            np.arange(len(syll_include)), syll_names, rotation=90\n",
    "        )\n",
    "\n",
    "    # saving the figures\n",
    "    # saving the figure\n",
    "    if save_dir is not None:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    else:\n",
    "        save_dir = os.path.join(project_dir, model_name, \"figures\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    fig.savefig(os.path.join(save_dir, \"transition_matrices.pdf\"))\n",
    "    fig.savefig(os.path.join(save_dir, \"transition_matrices.png\"))\n",
    "    fig.savefig(os.path.join(save_dir, \"transition_matrices.svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c92a9-20d3-481a-bd37-a869174846b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize='bigram' # normalization method (\"bigram\", \"rows\" or \"columns\")\n",
    "\n",
    "trans_mats, usages, groups, syll_include=kpms.generate_transition_matrices(\n",
    "    project_dir, model_name, normalize=normalize,\n",
    "    min_frequency=0.005 # minimum syllable frequency to include\n",
    ")    \n",
    "print(groups)\n",
    "\n",
    "# rearrange trans_mats in the similarity groups\n",
    "new_syll_include = syll_sim\n",
    "new_trans_mats = []\n",
    "for ii in range(len(trans_mats)):\n",
    "    new_trans_mats.append(trans_mats[ii][syll_sim][:,syll_sim])\n",
    "    \n",
    "visualize_transition_bigram_svg(\n",
    "    project_dir, model_name, groups, new_trans_mats, new_syll_include, normalize=normalize, \n",
    "    show_syllable_names=False # label syllables by index (False) or index and name (True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317b30a-22f9-4f7a-8c80-3f3693705adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.plot_transition_graph_group(\n",
    "    project_dir, model_name, \n",
    "    groups, trans_mats, usages, new_syll_include, \n",
    "    layout='circular',        # transition graph layout (\"circular\" or \"spring\")\n",
    "    show_syllable_names=False # label syllables by index (False) or index and name (True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b234e-b9d5-49ce-9426-51d6209dd545",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.plot_transition_graph_difference(project_dir, model_name,\n",
    "                                      groups, trans_mats, usages, new_syll_include, \n",
    "                                      layout='circular',show_syllable_names=False) # transition graph layout (\"circular\" or \"spring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bcea1-501f-443c-aaf9-5c518c6f2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.plot_transition_graph_difference(project_dir, model_name,\n",
    "                                      groups, trans_mats, usages, new_syll_include, \n",
    "                                      layout='circular',show_syllable_names=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2521db62-0d82-4382-8161-195d886e44c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a new index_data containing subject ID \n",
    "import os\n",
    "index_file = os.path.join(project_dir, \"index.csv\")\n",
    "if not os.path.exists(index_file):\n",
    "    generate_index(project_dir, model_name, index_file)\n",
    "\n",
    "index_data = pd.read_csv(index_file, index_col=False)\n",
    "sub_index_data = pd.DataFrame({\n",
    "    'name': index_data['name'],\n",
    "    'group': index_data['name']\n",
    "})\n",
    "sub_index_data\n",
    "sub_index_file = os.path.join(project_dir, \"sub_index.csv\")\n",
    "sub_index_data.to_csv(sub_index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c250c2-6ab7-4a9c-9fa8-c14c5dc20648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to calculate entropy\n",
    "# also considering usage? (ref, Datta, 2015 paper)\n",
    "def get_entropy(transition_matrix, usage, epsilon):\n",
    "    # calculate entropy for a 2D matrix\n",
    "    transition_matrix = np.where(transition_matrix == 0, epsilon, transition_matrix)\n",
    "    transition_matrix = np.where(np.isnan(transition_matrix), epsilon, transition_matrix)\n",
    "    # Calculate entropy using the formula\n",
    "    #print(usage.shape)\n",
    "    #print(transition_matrix.shape)\n",
    "    entropy = -np.sum(usage *transition_matrix * np.log2(transition_matrix))\n",
    "\n",
    "    # get individual contribution to the transitions\n",
    "    size_x = transition_matrix.shape[0]\n",
    "    size_y = transition_matrix.shape[1]\n",
    "    entropy_ind = np.zeros((size_x, size_y))\n",
    "\n",
    "    for ii in range(size_x):\n",
    "        #print(ii)\n",
    "        for jj in range(size_y):\n",
    "            #print(usage[0][ii]*transition_matrix[ii,jj]* np.log2(transition_matrix[ii,jj]))\n",
    "            entropy_ind[ii,jj] = -usage[ii]*transition_matrix[ii,jj]* np.log2(transition_matrix[ii,jj])\n",
    "    return entropy, entropy_ind\n",
    "\n",
    "# test_mat = np.full((25,25), 1/25)\n",
    "# usage = np.full((1,25), 1/25)\n",
    "# ent, ent_ind = get_entropy(test_mat, usage, 1e-12)\n",
    "# print(ent)\n",
    "# print(ent_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54694dae-58ee-49e4-9e4b-eda6a3be2fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate entropy for the whole session\n",
    "from keypoint_moseq.io import load_results\n",
    "from jax_moseq.utils import get_durations, get_frequencies\n",
    "import numpy as np\n",
    "\n",
    "normalize='columns' # normalization method (\"bigram\", \"rows\" or \"columns\")\n",
    "min_frequency = 0.005\n",
    "epsilon=1e-12\n",
    "entropyWhole = np.zeros((len(sub_index_data), 1))\n",
    "\n",
    "trans_mats, usages = None, None\n",
    "    # index file\n",
    "    #index_data = pd.read_csv(index_file, index_col=False)\n",
    "\n",
    "label_group = list(sub_index_data.group.values)\n",
    "recordings = list(sub_index_data.name.values)\n",
    "group = sorted(list(sub_index_data.group.unique()))\n",
    "    #print(\"Group(s):\", \", \".join(group)) \n",
    "save_results_path = os.path.join(project_dir, model_name,'results.h5')\n",
    "    # load model reuslts\n",
    "results_dict = load_results(path=save_results_path)\n",
    "    #print(results_dict)\n",
    "    \n",
    "    # filter out syllables by freqency (using overall results!)\n",
    "    \n",
    "model_labels = [results_dict[recording][\"syllable\"] for recording in recordings]\n",
    "    #print(model_labels)\n",
    "frequencies = get_frequencies(model_labels)\n",
    "syll_include = np.where(frequencies > min_frequency)[0]\n",
    "\n",
    "    \n",
    "trans_mats, usage = kpms.get_group_trans_mats(\n",
    "    model_labels,\n",
    "    label_group,\n",
    "    group,\n",
    "    syll_include=syll_include,\n",
    "    normalize=normalize,\n",
    ")\n",
    "groups = group\n",
    "    #print(trans_mats)\n",
    "# rearrange trans_mats in the similarity groups\n",
    "new_syll_include = syll_sim\n",
    "new_trans_mats = []\n",
    "#print(len(trans_mats))\n",
    "x = len(trans_mats)\n",
    "y = len(trans_mats[0])\n",
    "entropy_ind = np.zeros((x,y,len(sub_index_data)))\n",
    "for ii in range(len(trans_mats)):\n",
    "        #rint(ii)\n",
    "    #new_trans_mats.append(trans_mats[ii][syll_sim][:,syll_sim])\n",
    "    entropyWhole[ii], entropy_ind[:,:,ii]= get_entropy(trans_mats[ii], usage[ii],epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60283f60-c0c5-4684-bf82-e263e68300af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save entropy\n",
    "data = {\n",
    "    'animal':sub_index_data['name'],\n",
    "    'entropy':entropyWhole[:,0]\n",
    "}\n",
    "dataDF = pd.DataFrame(data)\n",
    "save_name = \"entropy_wholesession.csv\"\n",
    "save_path = os.path.join(project_dir, model_name,save_name)\n",
    "dataDF.to_csv(save_path)\n",
    "\n",
    "# save the data frame\n",
    "x = entropy_ind.shape[0]\n",
    "y = entropy_ind.shape[1]\n",
    "z = entropy_ind.shape[2]\n",
    "data = {\n",
    "    'animal':sub_index_data['name'],\n",
    "    'entropy':entropy_ind.reshape(x*y,z)\n",
    "}\n",
    "dataDF = pd.DataFrame(entropy_ind.reshape(x*y,z), columns=sub_index_data['name'])\n",
    "save_name = \"entropy_pairs_wholesession.csv\"\n",
    "save_path = os.path.join(project_dir, model_name,save_name)\n",
    "dataDF.to_csv(save_path)\n",
    "# save entropy for individual syllable pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132d5b7-8bad-4b56-baea-1cacd66fa6f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MGRPR data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "savefigpath = os.path.join(project_dir, model_name,'figures')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "fig.suptitle(\"Entropy of transitions - whole session\")\n",
    "# make the plot\n",
    "WTColor = (255 / 255, 189 / 255, 53 / 255)\n",
    "MutColor = (63 / 255, 167 / 255, 150 / 255)\n",
    "colors = [WTColor, MutColor]\n",
    "\n",
    "\n",
    "mat1 = entropyWhole[index_data['group']=='C'][:,0]\n",
    "mat2= entropyWhole[index_data['group']=='K'][:,0]\n",
    "statistic,p=mannwhitneyu(mat1,mat2)\n",
    "print(p)\n",
    "ax.violinplot([mat1, mat2], showmedians = True)\n",
    "vp=ax.set_xticks([1, 2], ['Ctrl', 'cKO'])\n",
    "\n",
    "fig.savefig(os.path.join(savefigpath, 'Entropy whole session.png'))\n",
    "fig.savefig(os.path.join(savefigpath, 'Entropy whole session.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5279a-316b-4334-a2c4-47ccad25597d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_group_trans_mats_custom(labels, label_group, group, syll_include, normalize=\"bigram\"):\n",
    "    from jax_moseq.utils import get_frequencies\n",
    "    \"\"\"Get the transition matrices for each group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : list or np.ndarray\n",
    "        recording state lists\n",
    "    label_group : list or np.ndarray\n",
    "        the group labels for each recording\n",
    "    group : list or np.ndarray\n",
    "        the groups in the project\n",
    "    max_sylls : int\n",
    "        the maximum number of syllables to include\n",
    "    normalize : str, optional\n",
    "        the method to normalize the transition matrix, by default 'bigram'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trans_mats : list\n",
    "        the list of transition matrices for each group\n",
    "    frequencies : list\n",
    "        the list of syllable frequencies for each group\n",
    "    \"\"\"\n",
    "    trans_mats = []\n",
    "    frequencies = []\n",
    "\n",
    "    # Computing transition matrices for each given group\n",
    "    for plt_group in group:\n",
    "        # list of syll labels in recordings in the group\n",
    "        use_labels = [lbl for lbl, grp in zip(labels, label_group) if grp == plt_group]\n",
    "        # find stack np array shape\n",
    "        row_num = len(use_labels)\n",
    "        max_len = max([len(lbl) for lbl in use_labels])\n",
    "        # Get recordings to include in trans_mat\n",
    "        # subset only syllable included\n",
    "        trans_mats.append(\n",
    "            kpms.get_transition_matrix(use_labels, normalize=normalize, combine=True)[\n",
    "                syll_include, :\n",
    "            ][:, syll_include]\n",
    "        )\n",
    "\n",
    "        # Getting frequency information for node scaling\n",
    "        group_frequencies = get_frequencies(use_labels)[syll_include]\n",
    "\n",
    "        frequencies.append(group_frequencies)\n",
    "    return trans_mats, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541fce06-df13-4ac5-95df-6b1dbfcb11e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bootstrap(data, dim, dim0, n_sample=1000):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    data: data matrix for bootstrap\n",
    "    dim: the dimension for bootstrap, should be data.shape[1]\n",
    "    dim0: the dimension untouched, shoud be data.shape[0]\n",
    "    n_sample: number of samples for bootstrap. default: 1000\n",
    "    output:\n",
    "    bootRes={'bootAve','bootHigh','bootLow'}\n",
    "    \"\"\"\n",
    "    # Resample the rows of the matrix with replacement\n",
    "    if len(data)>0:  # if input data is not empty\n",
    "        bootstrap_indices = np.random.choice(data.shape[dim], size=(n_sample, data.shape[dim]), replace=True)\n",
    "        #print(data.shape[dim])\n",
    "        # Bootstrap the matrix along the chosen dimension\n",
    "        bootstrapped_matrix = np.take(data, bootstrap_indices, axis=dim)\n",
    "        print(bootstrapped_matrix.shape)\n",
    "        meanBoot = np.nanmedian(bootstrapped_matrix,2)\n",
    "        print(meanBoot.shape)\n",
    "        bootAve = np.nanmedian(bootstrapped_matrix, axis = (1,2))\n",
    "        bootHigh = np.nanpercentile(meanBoot, 97.5, axis=1)\n",
    "        bootLow = np.nanpercentile(meanBoot, 2.5, axis=1)\n",
    "\n",
    "    else:  # return nans\n",
    "        bootAve = np.full(dim0, np.nan)\n",
    "        bootLow = np.full(dim0, np.nan)\n",
    "        bootHigh = np.full(dim0, np.nan)\n",
    "        # bootstrapped_matrix = np.array([np.nan])\n",
    "\n",
    "    # bootstrapped_2d = bootstrapped_matrix.reshape(80,-1)\n",
    "    # need to find a way to output raw bootstrap results\n",
    "    tempData = {'bootAve': bootAve, 'bootHigh': bootHigh, 'bootLow': bootLow}\n",
    "    index = np.arange(len(bootAve))\n",
    "    bootRes = pd.DataFrame(tempData, index)\n",
    "\n",
    "    return bootRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd06794-c3a7-40f9-aea9-ce0ca09c493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine grooming bouts\n",
    "frame_idx = np.unique(moseq_df['frame_index'])\n",
    "fps=40\n",
    "t_step = 5*60*fps\n",
    "num_window = int(np.ceil(len(frame_idx)/t_step))\n",
    "\n",
    "sessions = np.unique(moseq_df['name'])\n",
    "sessions = sub_index_data['name']\n",
    "fps = 40\n",
    "\n",
    "\n",
    "grooming_syl = [4,11, 12,13, 18, 26]\n",
    "total_grooming_time = np.zeros(len(sessions))\n",
    "total_grooming_bouts = np.zeros(len(sessions))\n",
    "grooming_bouts_duration = {}  # a dictionary to store the duration\n",
    "grooming_time_5window = np.zeros((len(sessions), num_window))\n",
    "grooming_bouts_5window = np.zeros((len(sessions), num_window))           \n",
    "\n",
    "for idx,ses in enumerate(sessions):\n",
    "    time  = 0\n",
    "    bouts = 0\n",
    "    grooming_bouts_duration[ses] = []\n",
    "    prev_syl = np.nan\n",
    "    duration = 0\n",
    "    for ss in results[ses]['syllable']:\n",
    "        if ss in grooming_syl:\n",
    "            time += 1\n",
    "            duration += 1\n",
    "            if prev_syl not in grooming_syl:\n",
    "                bouts += 1\n",
    "                grooming_bouts_duration[ses].append(duration/fps)\n",
    "                duration = 0    \n",
    "        prev_syl = ss\n",
    "    total_grooming_time[idx] = time/fps\n",
    "    total_grooming_bouts[idx] = bouts\n",
    "    if duration > 0:\n",
    "        grooming_bouts_duration[ses].append(duration/fps)\n",
    "    grooming_bouts_duration[ses] = grooming_bouts_duration[ses][1:]     \n",
    "    \n",
    "print(total_grooming_time)\n",
    "print(total_grooming_bouts)\n",
    "data = {\n",
    "    'animal':sub_index_data['name'],\n",
    "    'grooming_time':total_grooming_time,\n",
    "    'grooming_bouts':total_grooming_bouts\n",
    "}\n",
    "dataDF = pd.DataFrame(data)\n",
    "save_name = \"grooming.csv\"\n",
    "save_path = os.path.join(project_dir, model_name,save_name)\n",
    "dataDF.to_csv(save_path)\n",
    "print(grooming_bouts_duration[ses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a235d-4755-45a8-b8e3-4bc86a04169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MGRPR\n",
    "\n",
    "# make plots\n",
    "from scipy.stats import mannwhitneyu\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "fig.suptitle(\"Total grooming time - whole session\")\n",
    "# make the plot\n",
    "colors = [WTColor, MutColor]\n",
    "\n",
    "mat1 =total_grooming_time[index_data['group']=='C']\n",
    "mat2= total_grooming_time[index_data['group']=='K']\n",
    "statistic,p=mannwhitneyu(mat1,mat2)\n",
    "print(p)\n",
    "ax.violinplot([mat1, mat2], showmedians = True)\n",
    "vp=ax.set_xticks([1, 2], ['Ctrl', 'cKO'])\n",
    "\n",
    "savefigpath = os.path.join(project_dir, model_name,'figures')\n",
    "fig.savefig(os.path.join(savefigpath, 'Total grooming time.png'))\n",
    "fig.savefig(os.path.join(savefigpath, 'total grooming time.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Decoding analysis (Fig. 5P)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c68b052b72dd7b9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# decode the label from moseq and movement data\n",
    "# build the decoder on sessions? or different time frame of the sessions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keypoint_moseq.io import load_results\n",
    "from jax_moseq.utils import get_durations, get_frequencies\n",
    "normalize='columns' # normalization method (\"bigram\", \"rows\" or \"columns\")\n",
    "min_frequency = 0.005\n",
    "\n",
    "subject_geno_sex = index_data['group']\n",
    "group = np.unique(subject_geno_sex)\n",
    "\n",
    "trans_mats, usages = None, None\n",
    "    # index file\n",
    "#index_data = pd.read_csv(index_file, index_col=False)\n",
    "\n",
    "label_group = list(sub_index_data.group.values)\n",
    "recordings = list(sub_index_data.name.values)\n",
    "group = sorted(list(sub_index_data.group.unique()))\n",
    "    #print(\"Group(s):\", \", \".join(group)) \n",
    "save_results_path = os.path.join(project_dir, model_name,'results.h5')\n",
    "    # load model reuslts\n",
    "results_dict = load_results(path=save_results_path)\n",
    "    #print(results_dict)\n",
    "    \n",
    "    # filter out syllables by freqency (using overall results!)\n",
    "    \n",
    "model_labels = [results_dict[recording][\"syllable\"] for recording in recordings]\n",
    "    #print(model_labels)\n",
    "frequencies = get_frequencies(model_labels)\n",
    "syll_include = np.where(frequencies > min_frequency)[0]\n",
    "\n",
    "trans_mats, usage = kpms.get_group_trans_mats(\n",
    "    model_labels,\n",
    "    label_group,\n",
    "    group,\n",
    "    syll_include=syll_include,\n",
    "    normalize=normalize,\n",
    ")\n",
    "trans_array = np.array(trans_mats)\n",
    "n_subjects = len(usage)\n",
    "\n",
    "#transition = np.full((n_subjects,  trans_array.shape[1]*trans_array.shape[2]),0)\n",
    "#for i in range(n_subjects):\n",
    "#    transition[i, :] = trans_mats[i].flatten()\n",
    "\n",
    "\n",
    "animals = index_data['name']\n",
    "#print(animals)\n",
    "move_data = ['centroid_x', 'centroid_y','heading', 'angular_velocity', 'velocity_px_s']\n",
    "max_length = 150000\n",
    "#movement = {}\n",
    "\n",
    "\n",
    "# for idx, move in enumerate(move_data):\n",
    "#     #movement[move] = np.full((len(animals), max_length), 0)\n",
    "#     for aidx, aa in enumerate(animals):\n",
    "#         movement[move][aidx,0:len(moseq_df[move][moseq_df['name']==aa])] = moseq_df[move][moseq_df['name']==aa]\n",
    "movement = np.full((len(animals), len(move_data)*max_length), 0)\n",
    "for aidx, aa in enumerate(animals):\n",
    "    for idx, move in enumerate(move_data):\n",
    "        movement[aidx,idx*max_length:idx*max_length+len(moseq_df[move][moseq_df['name']==aa])] = moseq_df[move][moseq_df['name']==aa]\n",
    "\n",
    "# decoding only 'WT' and 'Mut'\n",
    "decoding_label = []\n",
    "for gg in subject_geno_sex:\n",
    "    print(gg)\n",
    "    if 'C' in gg:\n",
    "        decoding_label.append('WT')\n",
    "    elif 'K' in gg:\n",
    "    #elif 'KO' in gg:\n",
    "        #decoding_label.append('Mut')\n",
    "        decoding_label.append('KO')\n",
    "\n",
    "#print(decoding_label)\n",
    "#print(transition.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc37f12df941a3a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_nans(matrix):\n",
    "    nan_indices = []\n",
    "    for i, row in enumerate(matrix):\n",
    "        for j, value in enumerate(row):\n",
    "            if isinstance(value, float) and np.isnan(value):\n",
    "                nan_indices.append((i, j))\n",
    "    return nan_indices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "521cb0311ece46a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove animal 8 for too many nans\n",
    "Index_to_keep = np.arange(len(decoding_label)) != 8\n",
    "print(Index_to_keep)\n",
    "decoding_label_new = decoding_label[0:8] + decoding_label[9:]\n",
    "print(decoding_label_new)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "feab77becf2d35df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# run 20 times to get an average\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "n_repeats = 20\n",
    "classifier = 'RandomForest'\n",
    "decoder_transition = run_decoder(transitions, decoding_label, classifier, 42, n_repeats)\n",
    "print(decoder_transition)\n",
    "print('Decode transition Done')\n",
    "\n",
    "decoder_usage = run_decoder(usage, decoding_label, classifier, 42, n_repeats)\n",
    "print(decoder_usage)\n",
    "print('Decode usage Done')\n",
    "\n",
    "decoder_movement = run_decoder(movement, decoding_label, classifier, 42, n_repeats)\n",
    "print(decoder_movement)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de23b35e21e391c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "n_repeats = 20\n",
    "animalIndex = np.arange(len(decoding_label))\n",
    "WTIdx = animalIndex[np.array(decoding_label)=='WT']\n",
    "KOIdx = animalIndex[np.array(decoding_label)=='KO']\n",
    "decode_transition = {}\n",
    "decode_usage = {}\n",
    "decode_movement = {}\n",
    "decode_transition['accuracy'] = np.zeros((n_repeats))\n",
    "decode_transition['ctrl_accuracy'] =np.zeros((n_repeats))\n",
    "decode_usage['accuracy'] = np.zeros((n_repeats))\n",
    "decode_usage['ctrl_accuracy'] =np.zeros((n_repeats))\n",
    "decode_movement['accuracy'] = np.zeros((n_repeats))\n",
    "decode_movement['ctrl_accuracy'] =np.zeros((n_repeats))\n",
    "\n",
    "WTIdx_touse = random.sample(list(WTIdx), len(KOIdx))\n",
    "idx_touse = sorted(WTIdx_touse+list(KOIdx))\n",
    "#print(decoding_label[idx_touse])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4ccefd9f6ccf8f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for rr in range(n_repeats):\n",
    "    print(rr)\n",
    "    random.seed(rr)\n",
    "    WTIdx_touse = random.sample(list(WTIdx), len(KOIdx))\n",
    "    idx_touse = sorted(WTIdx_touse+list(KOIdx))\n",
    "    print(idx_touse)\n",
    "    new_label = [decoding_label[ii] for ii in idx_touse]\n",
    "    new_usage = [usage[ii] for ii in idx_touse]\n",
    "\n",
    "    decoder_transition = run_decoder(transitions[idx_touse,:], new_label, classifier, rr, 1)\n",
    "    decode_transition['accuracy'][rr] = decoder_transition['accuracy'][0]\n",
    "    decode_transition['ctrl_accuracy'][rr] = decoder_transition['ctrl_accuracy'][0]\n",
    "    decoder_usage = run_decoder(new_usage, new_label, classifier, rr,1)\n",
    "    decode_usage['accuracy'][rr] = decoder_usage['accuracy'][0]\n",
    "    decode_usage['ctrl_accuracy'][rr] = decoder_usage['ctrl_accuracy'][0]\n",
    "    decoder_movement = run_decoder(movement[idx_touse,:], new_label, classifier, rr,1)\n",
    "    decode_movement['accuracy'][rr] = decoder_movement['accuracy'][0]\n",
    "    decode_movement['ctrl_accuracy'][rr] = decoder_movement['ctrl_accuracy'][0]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32838255bd1b253e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save the data\n",
    "data = {\n",
    "    'transition_decode_accuracy': decode_transition['accuracy'],\n",
    "    'transition_decode_control': decode_transition['ctrl_accuracy'],\n",
    "    'usage_decode_accuracy': decode_usage['accuracy'],\n",
    "    'usage_decode_control': decode_usage['ctrl_accuracy'],\n",
    "    'movement_decode_accuracy':decode_movement['accuracy'],\n",
    "    'movement_decode_ctrl':decode_movement['ctrl_accuracy']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "savefile = os.path.join(project_dir, model_name,'decode_results_RF.csv')\n",
    "df.to_csv(savefile)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc3973f21e48b44e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "data = [decode_transition['accuracy'],\n",
    "        decode_usage['accuracy'],\n",
    "        decode_movement['accuracy']]\n",
    "\n",
    "ax=sns.boxplot(data=data)\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "ax.set_xticklabels(['Transition', 'Usage', 'Movement']) \n",
    "ax.set_ylabel('Decoding accuracy')\n",
    "savefigpath = os.path.join(project_dir, model_name, 'figures')\n",
    "plt.savefig(os.path.join(savefigpath,'Decoding accuracy.png'))\n",
    "plt.savefig(os.path.join(savefigpath,'Decoding accuracy.svg'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbba7f211dc181bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
